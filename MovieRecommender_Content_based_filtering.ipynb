{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOVIE RECOMMENDER SYSTEM - CONTENT BASED RECOMMENDATION\n",
    "\n",
    "#### SREENATH S\n",
    "\n",
    "**NOTE: It is assumed that all the required input files are present in the same folder where this notebook is copied to.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the project Movie Recommendation System. Basic functionality of this notebook is to perform the content based filtering. \n",
    "\n",
    "1. Get movie metadata dataset.<br>\n",
    "2. Get user rating dataset, both trainset and testset<br>\n",
    "3. Apply TfIdf vectorizer on the Movie Metadata dataset. We are taking only two columns \"Title\" and \"movie_keywords\"<br>\n",
    "4. Index the TfIdf DF with imdbId<br>\n",
    "5. Generate user profiles for each user as follows:<br>\n",
    "   a. Filter all the movies interacted by the user as part of training set.<br>\n",
    "   b. Create a sparse matrix, in which each row correspond to the TfIdf representation of the movie user watched<br>\n",
    "   c. Compute wighted average by mutiplying above matrix (step 5.b) with user ratings.<br>\n",
    "   d. Normalize the data in the weighted average matrix.<br>\n",
    "6. Compute the recommendation for every user as follows:\n",
    "   a. Compute the cosine similarity between the user's weighted average vector with TfIdf representation of each movie.\n",
    "   b. Filter out the movies already watched by the ser.\n",
    "   c. Predict the TopN movies with highest similarity score.\n",
    "\n",
    "**Notebook from the walkthrough session is used as base version, changes are made as required on top of the initial version**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the packages as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "import import_ipynb\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from configs import MODEL_CONTENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading other modules which are created as part of Movie Recommendation system. Other modules of interest are:\n",
    "1. MovieRecommender_TrainTestDataGenerator\n",
    "2. MovieRecommeder_evaluations\n",
    "\n",
    "Please note that disabled print functionality for this cell, otherwise it will be showing print statements from these modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import MovieRecommender_TrainTestDataGenerator as DataGen\n",
    "import MovieRecommeder_evaluations as ModelEval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the movie metadata from the MovieRecommender_TrainTestDataGenerator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8989, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_meta_data = DataGen.get_movie_metadata()\n",
    "movie_meta_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the user ratings train dataset, and user ratings test dataset. We will be using it for creating the wighter user profile vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_train_df, user_ratings_test_df = DataGen.train_test_user_behaviour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring and printing the datasets imported, to make sure everything imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>73</td>\n",
       "      <td>112864</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49661</th>\n",
       "      <td>472</td>\n",
       "      <td>120906</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48470</th>\n",
       "      <td>584</td>\n",
       "      <td>119116</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33782</th>\n",
       "      <td>18</td>\n",
       "      <td>117913</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80144</th>\n",
       "      <td>614</td>\n",
       "      <td>80549</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  imdbId  rating\n",
       "2457       73  112864     3.5\n",
       "49661     472  120906     5.0\n",
       "48470     584  119116     3.5\n",
       "33782      18  117913     4.0\n",
       "80144     614   80549     2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>movie_genre</th>\n",
       "      <th>movie_production</th>\n",
       "      <th>movie_keywords</th>\n",
       "      <th>spoken_language</th>\n",
       "      <th>imdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Animation Comedy Family</td>\n",
       "      <td>Pixar Animation Studios</td>\n",
       "      <td>jealousy toy boy friendship friends rivalry bo...</td>\n",
       "      <td>en</td>\n",
       "      <td>114709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Adventure Fantasy Family</td>\n",
       "      <td>TriStar Pictures,Teitler Film,Interscope Commu...</td>\n",
       "      <td>board game disappearance based on children's b...</td>\n",
       "      <td>en fr</td>\n",
       "      <td>113497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Romance Comedy</td>\n",
       "      <td>Warner Bros.,Lancaster Gate</td>\n",
       "      <td>fishing best friend duringcreditsstinger old men</td>\n",
       "      <td>en</td>\n",
       "      <td>113228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Comedy Drama Romance</td>\n",
       "      <td>Twentieth Century Fox Film Corporation</td>\n",
       "      <td>based on novel interracial relationship single...</td>\n",
       "      <td>en</td>\n",
       "      <td>114885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Sandollar Productions,Touchstone Pictures</td>\n",
       "      <td>baby midlife crisis confidence aging daughter ...</td>\n",
       "      <td>en</td>\n",
       "      <td>113041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_language               original_title                        title  \\\n",
       "0                en                    Toy Story                    Toy Story   \n",
       "1                en                      Jumanji                      Jumanji   \n",
       "2                en             Grumpier Old Men             Grumpier Old Men   \n",
       "3                en            Waiting to Exhale            Waiting to Exhale   \n",
       "4                en  Father of the Bride Part II  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                movie_genre  \\\n",
       "0   Animation Comedy Family   \n",
       "1  Adventure Fantasy Family   \n",
       "2            Romance Comedy   \n",
       "3      Comedy Drama Romance   \n",
       "4                    Comedy   \n",
       "\n",
       "                                    movie_production  \\\n",
       "0                            Pixar Animation Studios   \n",
       "1  TriStar Pictures,Teitler Film,Interscope Commu...   \n",
       "2                        Warner Bros.,Lancaster Gate   \n",
       "3             Twentieth Century Fox Film Corporation   \n",
       "4          Sandollar Productions,Touchstone Pictures   \n",
       "\n",
       "                                      movie_keywords spoken_language  imdbId  \n",
       "0  jealousy toy boy friendship friends rivalry bo...              en  114709  \n",
       "1  board game disappearance based on children's b...           en fr  113497  \n",
       "2   fishing best friend duringcreditsstinger old men              en  113228  \n",
       "3  based on novel interracial relationship single...              en  114885  \n",
       "4  baby midlife crisis confidence aging daughter ...              en  113041  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_meta_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'imdbId', 'rating'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how many unique movies in movie meta data df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8989"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_meta_data.imdbId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_imdbId = set(movie_meta_data.imdbId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_train_df.imdbId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there are a total of 8989 movies out of which 8500 are part of train dataset, which is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imdbId = set(user_ratings_train_df.imdbId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_imdbId.intersection(train_imdbId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4212"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_test_df.imdbId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary there are only 4212 movies are part of the testing datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imdbId = set(user_ratings_test_df.imdbId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_imdbId.intersection(test_imdbId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model with vectors size 1500 (i.e.top max_features ordered by term frequency across the corpus). We will be ignoring the terms with document frequency lower that 0.003 and higher than 0.5. Also we will be taking. both unigram and bigram for this analysis. Stop words are instantiated from the nltk and is passed to the vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=0.5, max_features=1500,\n",
      "                min_df=0.003, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True,\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
      "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
      "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
      "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
      "                            'itself', ...],\n",
      "                strip_accents=None, sublinear_tf=False,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "                vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# model class\n",
    "vectorizer = TfidfVectorizer(analyzer='word',min_df=0.003,max_df=0.5,max_features=1500,ngram_range=(1, 2),stop_words=stopwords_list)\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a list of all movies (we will be having a list of imdbIds)<br>\n",
    "Will fit the vectorizer on Title and movie_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_meta_data['overview'] = movie_meta_data['overview'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = movie_meta_data['imdbId'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(movie_meta_data.title+\"\"+movie_meta_data.movie_keywords)\n",
    "tfidf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see thers are only 731 features as per the min max ferquency we specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1970s', '19th', '19th century', '3d', 'abuse', 'accident', 'action', 'actor', 'addiction', 'adoption', 'adult', 'adult novel', 'adultery', 'adventure', 'affair', 'aftercreditsstinger', 'aftercreditsstinger duringcreditsstinger', 'age', 'agent', 'air', 'airplane', 'airport', 'alcohol', 'alcoholic', 'alien', 'alien invasion', 'america', 'american', 'anarchic', 'anarchic comedy', 'ancient', 'angeles', 'animal', 'animation', 'anime', 'anti', 'apartment', 'apocalypse', 'apocalyptic', 'apocalyptic dystopia', 'army', 'art', 'artist', 'arts', 'assassin', 'assassination', 'astronaut', 'asylum', 'attack', 'attempt', 'australia', 'author', 'baby', 'back', 'bad', 'ball', 'band', 'bank', 'bar', 'baseball', 'based', 'based comic', 'based novel', 'based play', 'based true', 'based tv', 'based video', 'based young', 'battle', 'beach', 'bear', 'beauty', 'best', 'best friend', 'betrayal', 'big', 'biography', 'birth', 'black', 'blackmail', 'blood', 'blue', 'boat', 'body', 'bomb', 'book', 'boss', 'boxer', 'boxing', 'boy', 'boyfriend', 'bride', 'bridge', 'british', 'broken', 'brother', 'brother brother', 'brother relationship', 'brother sister', 'brutality']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_feature_names[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8989, 731)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_df = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8989, 731)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_df['imdbId'] = item_ids\n",
    "tfidf_matrix_df = tfidf_matrix_df.set_index('imdbId')\n",
    "tfidf_matrix_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1970s</th>\n",
       "      <th>19th</th>\n",
       "      <th>19th century</th>\n",
       "      <th>3d</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accident</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>addiction</th>\n",
       "      <th>adoption</th>\n",
       "      <th>...</th>\n",
       "      <th>world war</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>york city</th>\n",
       "      <th>young</th>\n",
       "      <th>young adult</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdbId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113228</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1970s  19th  19th century   3d  abuse  accident  action  actor  \\\n",
       "imdbId                                                                   \n",
       "114709    0.0   0.0           0.0  0.0    0.0       0.0     0.0    0.0   \n",
       "113497    0.0   0.0           0.0  0.0    0.0       0.0     0.0    0.0   \n",
       "113228    0.0   0.0           0.0  0.0    0.0       0.0     0.0    0.0   \n",
       "114885    0.0   0.0           0.0  0.0    0.0       0.0     0.0    0.0   \n",
       "113041    0.0   0.0           0.0  0.0    0.0       0.0     0.0    0.0   \n",
       "\n",
       "        addiction  adoption  ...  world war  writer  year  york  york city  \\\n",
       "imdbId                       ...                                             \n",
       "114709        0.0       0.0  ...        0.0     0.0   0.0   0.0        0.0   \n",
       "113497        0.0       0.0  ...        0.0     0.0   0.0   0.0        0.0   \n",
       "113228        0.0       0.0  ...        0.0     0.0   0.0   0.0        0.0   \n",
       "114885        0.0       0.0  ...        0.0     0.0   0.0   0.0        0.0   \n",
       "113041        0.0       0.0  ...        0.0     0.0   0.0   0.0        0.0   \n",
       "\n",
       "        young  young adult  younger  youth  zombie  \n",
       "imdbId                                              \n",
       "114709    0.0          0.0      0.0    0.0     0.0  \n",
       "113497    0.0          0.0      0.0    0.0     0.0  \n",
       "113228    0.0          0.0      0.0    0.0     0.0  \n",
       "114885    0.0          0.0      0.0    0.0     0.0  \n",
       "113041    0.0          0.0      0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 731 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make the above steps into a function so that it can be called from the Content Based Filtering Class. So the COntent Based Class can be made self suffiecient and it wont be dependent on any of the global variables created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD      : create_tfidf_matrix\n",
    "# INPUT       : NA.\n",
    "# DESCRIPTION : Returns a TfIdf Matrix by performing the following steps:. \n",
    "#               1. Get the movie metadata dataset\n",
    "#               2. Get the ratings data set-train\n",
    "#               3. Instantiate a TfIdf vectorizer with stop words for 'English'\n",
    "#               4. Fit the vectorizer on movie metadata features, Title and Keywords. This will yield a tfidf sparse matrix.\n",
    "#               5. Create a data frame from the sparse matrix output.\n",
    "#               6. Set the index of the DF as 'imdbId'\n",
    "def create_tfidf_matrix():\n",
    "    movie_meta_data = DataGen.get_movie_metadata()\n",
    "    user_ratings_train_df, user_ratings_test_df = DataGen.train_test_user_behaviour()\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',min_df=0.003,max_df=0.5,max_features=1500,ngram_range=(1, 2),stop_words=stopwords_list)\n",
    "    item_ids = movie_meta_data['imdbId'].tolist()\n",
    "    tfidf_matrix = vectorizer.fit_transform(movie_meta_data.title+\"\"+movie_meta_data.movie_keywords)\n",
    "    tfidf_feature_names = vectorizer.get_feature_names()\n",
    "    tfidf_matrix_df = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=tfidf_feature_names)\n",
    "    tfidf_matrix_df['imdbId'] = item_ids\n",
    "    tfidf_matrix_df = tfidf_matrix_df.set_index('imdbId')\n",
    "    return tfidf_matrix_df, tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to create the weighted user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD      : create_item_profiles\n",
    "# INPUT       : List of all item ids to be considered for creating the profile.\n",
    "# DESCRIPTION : Get the rows corresponding to each of the movies in the iput list. \n",
    "#               Stack it vertically and return the sparse matrix.\n",
    "def create_item_profiles(all_item_ids, tfidf_matrix):\n",
    "    \n",
    "    item_profiles_list = [tfidf_matrix[item_ids.index(x):item_ids.index(x)+1] for x in all_item_ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD      : generate_users_profiles\n",
    "# INPUT       : TfIdf Matrix.\n",
    "# DESCRIPTION : For every user in the training dataset, perform the following. \n",
    "#               Filter the movies watched by the user.\n",
    "#               Invoke create_item_profiles with the list of movies filtered above.\n",
    "#               Compute the wighted average vector for each user by mutiplying user ratings with the matrix returned by create_item_profiles\n",
    "#               Normalize the data.\n",
    "\n",
    "def generate_users_profiles(TfIdfMatrix):\n",
    "    user_ratings_train_df = DataGen.train_test_user_behaviour()[0]\n",
    "    user_behaviour_indexed_df = user_ratings_train_df.set_index('userId')\n",
    "    user_profiles = {}\n",
    "    for person_id in user_behaviour_indexed_df.index.unique():\n",
    "        # Filter the movies interacted by user\n",
    "        user_behaviour_person_df = user_behaviour_indexed_df.loc[person_id]\n",
    "        # Create the item profile matrix\n",
    "        user_item_profiles = create_item_profiles(user_behaviour_person_df['imdbId'], TfIdfMatrix)\n",
    "        # Get the user ratings vector\n",
    "        user_item_strengths = np.array(user_behaviour_person_df['rating']).reshape(-1,1)\n",
    "        # Weighted average of item profiles by the user_behaviour strength\n",
    "        user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "        user_profile_normalized = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "        # Store it on to the user_profile set\n",
    "        user_profiles[person_id] = user_profile_normalized\n",
    "        \n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the correctness of the above function by invoking it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Invoke the generate_users_profiles() to create user profile data\n",
    "TfIdfDF, TfIdfMatrix = create_tfidf_matrix()\n",
    "user_profiles = generate_users_profiles(TfIdfMatrix)\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02882835 0.00856112 0.00856112 0.         0.03223596 0.02113753\n",
      "  0.01351029 0.03791213 0.00916059 0.00340706 0.02155316 0.\n",
      "  0.02531783 0.01187935 0.02148889 0.05332248 0.02724138 0.05250307\n",
      "  0.0433457  0.01370486 0.03872674 0.0147711  0.02858992 0.0110799\n",
      "  0.03082857 0.00121231 0.0156084  0.11350479 0.04463024 0.04463024\n",
      "  0.00333713 0.04102523 0.04137946 0.04512172 0.01017047 0.01740467\n",
      "  0.01058502 0.01219099 0.01670856 0.01121853 0.0601521  0.06374564\n",
      "  0.01714152 0.03079727 0.03204589 0.01137682 0.00501587 0.01514912\n",
      "  0.03208264 0.04742968 0.01695676 0.033104   0.00308042 0.00518507\n",
      "  0.02179618 0.00777938 0.03073505 0.00955398 0.00573716 0.01226112\n",
      "  0.09992833 0.00234071 0.06676847 0.02103683 0.02594992 0.01339461\n",
      "  0.         0.         0.04789131 0.03236571 0.00203087 0.00671723\n",
      "  0.02177413 0.01670444 0.01643529 0.05348671 0.03104512 0.01946954\n",
      "  0.04057754 0.03284045 0.0229174  0.0319363  0.0269355  0.0188169\n",
      "  0.02520829 0.04160455 0.03487652 0.01467232 0.00697282 0.01838594\n",
      "  0.00931916 0.02049156 0.04127768 0.0344953  0.01458769 0.05728275\n",
      "  0.01018443 0.0256812  0.01748322 0.03365493 0.0273021  0.0558593\n",
      "  0.01975296 0.01296041 0.02864588 0.00601471 0.00904351 0.06170094\n",
      "  0.00795593 0.01377401 0.01687827 0.01467961 0.03015794 0.01231044\n",
      "  0.01556015 0.02884576 0.01577898 0.01150558 0.1236691  0.03721547\n",
      "  0.01882469 0.04300832 0.04821156 0.01090154 0.00772997 0.02554445\n",
      "  0.06596442 0.01453702 0.05741907 0.03529672 0.01705376 0.02265457\n",
      "  0.01766088 0.02358241 0.01185336 0.08446173 0.01433573 0.00262653\n",
      "  0.03867213 0.02818779 0.01466132 0.01301988 0.02439425 0.02335324\n",
      "  0.01741581 0.01247929 0.00789347 0.03001999 0.01015474 0.01362616\n",
      "  0.0181496  0.0113273  0.03274528 0.01567249 0.02898744 0.002353\n",
      "  0.05780623 0.04174853 0.05473772 0.0169805  0.03149029 0.0511788\n",
      "  0.04120161 0.03214093 0.00776567 0.04454077 0.01222816 0.01060145\n",
      "  0.0339123  0.01475274 0.06328765 0.01294027 0.03290996 0.02610741\n",
      "  0.04291898 0.11496903 0.00617013 0.00471626 0.03071675 0.01659829\n",
      "  0.05764615 0.         0.02002978 0.11983892 0.01727504 0.01612981\n",
      "  0.00883032 0.00334316 0.00631786 0.01581538 0.02718456 0.05405861\n",
      "  0.02256804 0.00283338 0.00829776 0.04991013 0.01150514 0.09096893\n",
      "  0.02141562 0.01664306 0.04247352 0.05386543 0.048659   0.01126138\n",
      "  0.01170883 0.06789458 0.00280843 0.02866908 0.00367691 0.08732875\n",
      "  0.01106599 0.0353867  0.01460917 0.01253554 0.02696888 0.05623822\n",
      "  0.0173228  0.00678558 0.01186348 0.02129129 0.02129129 0.00992629\n",
      "  0.01026454 0.00377767 0.00610411 0.00451962 0.01845485 0.00667382\n",
      "  0.00690992 0.02680216 0.07555936 0.01356757 0.00224894 0.01409764\n",
      "  0.00429351 0.0460084  0.00336271 0.00818145 0.03154709 0.01303414\n",
      "  0.02078765 0.04847901 0.00513743 0.00596474 0.02875093 0.00407972\n",
      "  0.0297915  0.29536886 0.04797089 0.01184616 0.02663112 0.01958121\n",
      "  0.02419062 0.03903637 0.02162649 0.00430507 0.0054079  0.03875376\n",
      "  0.00754143 0.00547795 0.00348945 0.02117294 0.01115626 0.00744696\n",
      "  0.02422633 0.03773844 0.0257426  0.08252799 0.00681579 0.01530945\n",
      "  0.01655393 0.02863425 0.01281877 0.0590808  0.02312721 0.01052222\n",
      "  0.01419959 0.01967368 0.01458743 0.03142378 0.03450544 0.04267353\n",
      "  0.0296779  0.01635389 0.03364768 0.02587749 0.00696645 0.00726078\n",
      "  0.04224164 0.03493476 0.0315166  0.00604026 0.01951108 0.03450118\n",
      "  0.00261147 0.00624599 0.01122872 0.00320754 0.01157307 0.0151492\n",
      "  0.02312463 0.00308996 0.         0.04040093 0.06939437 0.05565866\n",
      "  0.01918762 0.01976301 0.00751779 0.01185539 0.03992045 0.02142848\n",
      "  0.0016192  0.02479338 0.02843699 0.02701367 0.01579964 0.01615924\n",
      "  0.02645898 0.0434746  0.03014024 0.01830668 0.0078434  0.01446187\n",
      "  0.04959832 0.02523064 0.02444473 0.07966983 0.05229514 0.0300581\n",
      "  0.00823009 0.01191645 0.15301427 0.1530992  0.01031788 0.02182367\n",
      "  0.03273389 0.03812515 0.00450426 0.01260285 0.00627391 0.02920662\n",
      "  0.00353152 0.05051977 0.02412074 0.01886203 0.02887441 0.01581765\n",
      "  0.0385603  0.02745824 0.01580142 0.02236017 0.0351728  0.03509378\n",
      "  0.01713567 0.04844197 0.038396   0.01327728 0.01269737 0.00934841\n",
      "  0.02733114 0.04050857 0.04308725 0.01471874 0.00423188 0.00308652\n",
      "  0.01315754 0.00514338 0.00184045 0.13898045 0.00350763 0.02559259\n",
      "  0.01470528 0.01380101 0.04119738 0.0412556  0.08145412 0.01758897\n",
      "  0.04238426 0.1819824  0.04011349 0.05789666 0.01292168 0.01574031\n",
      "  0.02652586 0.05312962 0.02259423 0.03635545 0.09080854 0.03132853\n",
      "  0.02979518 0.07458238 0.0333958  0.01029929 0.00307164 0.01566901\n",
      "  0.01230274 0.00311537 0.00316654 0.00252488 0.01471649 0.01900993\n",
      "  0.01391361 0.0113628  0.00865962 0.01911599 0.01399936 0.01877614\n",
      "  0.03722099 0.03162859 0.01453959 0.01046182 0.00967781 0.03114658\n",
      "  0.01350156 0.05795606 0.00986353 0.01764044 0.01508337 0.04383931\n",
      "  0.01073954 0.0077559  0.01945287 0.00577307 0.06799825 0.00165938\n",
      "  0.1045399  0.00708086 0.08132259 0.09341111 0.02779786 0.0030267\n",
      "  0.03498916 0.01391264 0.         0.02168505 0.03302256 0.01751627\n",
      "  0.04766601 0.03296988 0.09819953 0.01851944 0.05989136 0.0272497\n",
      "  0.05017633 0.003006   0.00547991 0.09495981 0.08052977 0.02400555\n",
      "  0.04811065 0.0054591  0.03351578 0.01336861 0.02089451 0.01144984\n",
      "  0.09027742 0.03956249 0.00184773 0.02665352 0.02478162 0.00805473\n",
      "  0.00939166 0.01507012 0.03285487 0.03295428 0.02818098 0.03162075\n",
      "  0.0095722  0.04366274 0.00952396 0.01050642 0.03538979 0.00655629\n",
      "  0.0133809  0.00935698 0.00233194 0.03872172 0.02558981 0.00978422\n",
      "  0.09195197 0.00302855 0.01800346 0.01319225 0.01984881 0.02651788\n",
      "  0.01231781 0.01900784 0.01742227 0.01230383 0.00664325 0.02186471\n",
      "  0.04136265 0.01160251 0.01030153 0.0350131  0.04113436 0.00860274\n",
      "  0.01208579 0.03104875 0.0140658  0.05430132 0.02242936 0.02602174\n",
      "  0.03230869 0.01370491 0.00823197 0.01347868 0.03340336 0.00318057\n",
      "  0.02408851 0.03630461 0.01634617 0.0262843  0.0425365  0.02389954\n",
      "  0.04165971 0.03426652 0.16270042 0.01328816 0.00550171 0.0110681\n",
      "  0.00758559 0.0216042  0.01977514 0.0033857  0.02142305 0.01554112\n",
      "  0.00727133 0.01216577 0.03167103 0.0029621  0.03677384 0.01988393\n",
      "  0.03867545 0.01552498 0.02954505 0.02420411 0.02067545 0.00277731\n",
      "  0.02482817 0.02464365 0.04094142 0.00659274 0.03580071 0.\n",
      "  0.         0.04964297 0.02581035 0.01405889 0.01405889 0.00958908\n",
      "  0.01759818 0.01874047 0.         0.00463757 0.02191909 0.01427856\n",
      "  0.10959573 0.00788995 0.01350933 0.02265941 0.08217028 0.00987141\n",
      "  0.00169956 0.01954066 0.01035715 0.         0.00665132 0.04745016\n",
      "  0.00202622 0.02863489 0.02657956 0.01195413 0.02149344 0.01980766\n",
      "  0.03905398 0.02871872 0.00961016 0.01222902 0.02827546 0.01899833\n",
      "  0.03955404 0.00809691 0.00802052 0.0406018  0.02913405 0.0187\n",
      "  0.03589657 0.08482833 0.04937545 0.01941658 0.00809412 0.02949033\n",
      "  0.02805645 0.03460189 0.01532534 0.02315746 0.02959104 0.0460649\n",
      "  0.04231117 0.02939114 0.00934001 0.01676292 0.02351205 0.06733132\n",
      "  0.020193   0.00848806 0.00814374 0.         0.03806285 0.06933997\n",
      "  0.02536962 0.02573744 0.00319718 0.06370846 0.02264591 0.02288923\n",
      "  0.02073944 0.00816347 0.05053756 0.05099132 0.00991085 0.04465593\n",
      "  0.04459788 0.03115356 0.01012138 0.00236146 0.         0.01489907\n",
      "  0.00262653 0.01041884 0.02808184 0.00817349 0.03791044 0.01775121\n",
      "  0.02269681 0.01058957 0.00429244 0.00953302 0.01662331 0.03816983\n",
      "  0.03402035 0.0183524  0.02627977 0.0294507  0.01096824 0.03527922\n",
      "  0.02879412 0.01470685 0.02642832 0.01824974 0.02254072 0.00977226\n",
      "  0.00499543 0.03022926 0.00960146 0.00930266 0.04603488 0.02589993\n",
      "  0.01222418 0.02680377 0.02540074 0.00918143 0.0263786  0.01962208\n",
      "  0.00736663 0.00266798 0.02349116 0.01617959 0.01259621 0.04091224\n",
      "  0.02623866 0.04658285 0.01301056 0.         0.01339455 0.014722\n",
      "  0.02227403 0.02564248 0.01724552 0.01576583 0.0326273  0.04779627\n",
      "  0.01140236 0.01080418 0.03091896 0.01104739 0.00900965 0.\n",
      "  0.03263338 0.00607789 0.0486355  0.00839569 0.07289521 0.01011732\n",
      "  0.00387913 0.01991858 0.01301272 0.00693329 0.0156737  0.18247614\n",
      "  0.04858369 0.01809331 0.02046665 0.02436678 0.05732327 0.0069812\n",
      "  0.03774872 0.0198724  0.02960488 0.01571531 0.03247224 0.0111818\n",
      "  0.00971684 0.01948524 0.10044479 0.07015865 0.01267887 0.04281946\n",
      "  0.07921661 0.05230474 0.05434418 0.00570806 0.09353056 0.04443133\n",
      "  0.01835498 0.00569177 0.01144984 0.02238625 0.00467098]]\n"
     ]
    }
   ],
   "source": [
    "#Let us print the vector for a user\n",
    "print(user_profiles[472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentFiltering:\n",
    "    \n",
    "    \n",
    "    def __init__(self, item_ids, items_df):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        self.TfIdfDF, self.tfidf_matrix = create_tfidf_matrix()\n",
    "        self.user_profiles = generate_users_profiles(self.tfidf_matrix)\n",
    "        \n",
    "    def compute_user_item_profile_similarity(self, person_id, topn=2000):\n",
    "        # Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(self.user_profiles[person_id], self.tfidf_matrix)\n",
    "\n",
    "        # Sort the movies based on similarity and get the topn movies\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        \n",
    "        # Sort the similar items by similarity\n",
    "        similar_items = [(item_ids[i], cosine_similarities[0,i]) for i in similar_indices]\n",
    "        similar_items = sorted(similar_items, key=lambda x: x[1], reverse = True)\n",
    "        return similar_items\n",
    "        \n",
    "    def get_item_recommendations(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self.compute_user_item_profile_similarity(user_id)\n",
    "        #Filter movies the user has already watched\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['imdbId', 'sim_score']).head(topn)\n",
    "        movie_dataset = self.items_df[['imdbId', 'title']]\n",
    "        \n",
    "        recommendations_df = pd.merge(left=recommendations_df, right=movie_dataset, left_on='imdbId', right_on='imdbId')\n",
    "        #recommendations_df\n",
    "        return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us instantiate the content based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender_model = ContentFiltering(item_ids, movie_meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check the prediction for a particular user, by invoking get_item_recommendations with userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content based recommendations: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>sim_score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60304</td>\n",
       "      <td>0.400069</td>\n",
       "      <td>2 or 3 Things I Know About Her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110395</td>\n",
       "      <td>0.382622</td>\n",
       "      <td>Love and a .45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165874</td>\n",
       "      <td>0.382622</td>\n",
       "      <td>The Mating Habits of the Earthbound Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159272</td>\n",
       "      <td>0.382388</td>\n",
       "      <td>Beautiful People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120831</td>\n",
       "      <td>0.368626</td>\n",
       "      <td>Slums of Beverly Hills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102721</td>\n",
       "      <td>0.361512</td>\n",
       "      <td>Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>355702</td>\n",
       "      <td>0.356105</td>\n",
       "      <td>Lords of Dogtown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101588</td>\n",
       "      <td>0.355322</td>\n",
       "      <td>City of Hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>460829</td>\n",
       "      <td>0.353727</td>\n",
       "      <td>INLAND EMPIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132910</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>The Crow: Salvation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbId  sim_score                                      title\n",
       "0   60304   0.400069             2 or 3 Things I Know About Her\n",
       "1  110395   0.382622                             Love and a .45\n",
       "2  165874   0.382622  The Mating Habits of the Earthbound Human\n",
       "3  159272   0.382388                           Beautiful People\n",
       "4  120831   0.368626                     Slums of Beverly Hills\n",
       "5  102721   0.361512                                      Proof\n",
       "6  355702   0.356105                           Lords of Dogtown\n",
       "7  101588   0.355322                               City of Hope\n",
       "8  460829   0.353727                              INLAND EMPIRE\n",
       "9  132910   0.350745                        The Crow: Salvation"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"content based recommendations: \\n\\n\")\n",
    "content_based_recommender_model.get_item_recommendations(472)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model on the train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users processed :  667\n",
      "overall metrics:\n",
      " {'model_type': 'content_based', 'recallscore@5': 0.14422241529105126, 'recallscore@10': 0.2359152576355009}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hitrate@5_count</th>\n",
       "      <th>hitrate@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recallscore@5</th>\n",
       "      <th>recallscore@10</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>372</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>0.134409</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>266</td>\n",
       "      <td>0.101504</td>\n",
       "      <td>0.180451</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>264</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>258</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>249</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.128514</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>214</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>185</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.156757</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>169</td>\n",
       "      <td>0.112426</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>156</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>41</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.427586</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hitrate@5_count  hitrate@10_count  interacted_count  recallscore@5  \\\n",
       "61               26                50               372       0.069892   \n",
       "62               27                48               266       0.101504   \n",
       "12               30                53               264       0.113636   \n",
       "17               14                31               258       0.054264   \n",
       "66               12                32               249       0.048193   \n",
       "41                7                22               214       0.032710   \n",
       "2                11                29               185       0.059459   \n",
       "50               19                30               169       0.112426   \n",
       "23               17                33               156       0.108974   \n",
       "79               41                62               145       0.282759   \n",
       "\n",
       "    recallscore@10  userId  \n",
       "61        0.134409     547  \n",
       "62        0.180451     624  \n",
       "12        0.200758      73  \n",
       "17        0.120155     564  \n",
       "66        0.128514      15  \n",
       "41        0.102804     468  \n",
       "2         0.156757     452  \n",
       "50        0.177515      30  \n",
       "23        0.211538     311  \n",
       "79        0.427586     213  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_overall_metrics, content_eval_results_df = ModelEval.model_evaluator.evaluate_model(content_based_recommender_model,MODEL_CONTENT)\n",
    "print('overall metrics:\\n', content_overall_metrics)\n",
    "content_eval_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
